{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3 - 7313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 0 - Importing Libraries\n",
    "\n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import sklearn.metrics as metrics\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "import json     \n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from gettext import install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 0 - Downloading data as CSV files from SQL and then importing into python. \n",
    "\n",
    "# Importing the CSV file. Column names will be automatically inferred from the header row.\n",
    "\n",
    "# Apartment\n",
    "df_apartment = pd.read_csv('Apartment.csv') \n",
    "\n",
    "# AnnualReport\n",
    "df_annualreport = pd.read_csv('AnnualReport.csv') \n",
    "\n",
    "# HousingAssociation\n",
    "df_housingassociation = pd.read_csv('HousingAssociation.csv') \n",
    "\n",
    "# Dropping features that will not be imputed\n",
    "df_annualreport = df_annualreport.drop(['long_term_debt_other', 'long_term_real_estate_debt', 'number_of_rental_units', 'plot_is_leased', 'savings', \n",
    "                                        'total_commercial_area', 'total_loan', 'total_rental_area'], axis=1)\n",
    "\n",
    "df_housingassociation = df_housingassociation.drop(['name', 'housing_coop_id'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1 - Merging the dataframes  \n",
    "\n",
    "# Renaming from housing_association_org_number to org_number in df_apartment\n",
    "df_apartment = df_apartment.rename(columns={'housing_association_org_number': 'org_number'}) \n",
    "\n",
    "# Reformating fiscal_year by pushing forward the one year, while preserves NaN\n",
    "df_annualreport['fiscal_year_plus_one'] = df_annualreport['fiscal_year'] + 1 \n",
    "\n",
    "# Convert sell_date column to datetime format \n",
    "df_apartment['sell_date'] = pd.to_datetime(df_apartment['sell_date']) \n",
    "\n",
    "# Extract the year from sell_date\n",
    "df_apartment['sell_year'] = df_apartment['sell_date'].dt.year.astype('int64') \n",
    "\n",
    "# Sort fiscal_year_plus_one and org_number in ascending order in df_annualreport\n",
    "df_annualreport = df_annualreport.sort_values(by=['fiscal_year_plus_one', 'org_number'])\n",
    "\n",
    "# Sort sell_year and org_number in ascending order in df_apartment \n",
    "df_apartment = df_apartment.sort_values(by=['sell_year','org_number']) \n",
    "\n",
    "# Merge df_apartment and df_annualreport with an asof merge\n",
    "# Assumption that the annual reports are posted at the end of December and people mostly see the annual reports from the year before \n",
    "df_apartment_with_annualreport = pd.merge_asof(\n",
    "    df_apartment, df_annualreport,\n",
    "    left_on='sell_year', right_on='fiscal_year_plus_one', # Match sell_year to fiscal_year_plus_one \n",
    "    by='org_number',                                      # Match on org_number before performing merge operation.\n",
    "    direction='backward')                                 # Backward search selects the last row in df_annualreport whose 'on' key is less than or equal to the left's key.\n",
    "\n",
    "# Merge df_apartment_with_annualreport with df_housingassociation on org_number\n",
    "df = pd.merge(df_apartment_with_annualreport, df_housingassociation, on='org_number', how='left') \n",
    "\n",
    "# Dropping irrelevant columns,  sell_date, fiscal_year and fiscal_year_plus_one are only used for STEP 1 above\n",
    "df = df.drop(['fiscal_year', 'sell_date', 'fiscal_year_plus_one'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Data Cleaning\n",
    "\n",
    "# Creating unique IDs for missing values in org_number\n",
    "\n",
    "# Define the starting number for new unique IDs\n",
    "starting_number = 100000 \n",
    "\n",
    "# Count the number of missing values in 'org_number', which is 69643 from data wrangler\n",
    "missing_count = df['org_number'].isna().sum() \n",
    "\n",
    "# Generate new unique numbers starting from 'starting_number'\n",
    "new_numbers = [f\"{str(100000 + i).zfill(6)}-0000\" for i in range(missing_count)] \n",
    "\n",
    "# Replace NaN values in 'org_number' with the new unique numbers\n",
    "df.loc[df['org_number'].isna(), 'org_number'] = new_numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Data Cleaning Continued \n",
    "\n",
    "# Filling one missing value in municipality, postcode, primary_area and region, respectively based on address.\n",
    "\n",
    "# Municipality\n",
    "df['municipality'] = df['municipality'].fillna('Umeå')\n",
    "\n",
    "# Postcode\n",
    "df['postcode'] = df['postcode'].fillna(90736.0) \n",
    "\n",
    "# Primary_area \n",
    "df['primary_area'] = df['primary_area'].fillna('Ålidhem') \n",
    "\n",
    "# Region\n",
    "df['region'] = df['region'].fillna('Västerbottens län')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Data Cleaning Continued \n",
    "\n",
    "# Filling missing values in location \n",
    "\n",
    "# Sorting the remaining municipalities manually and assigning them to either Norra Sverige or Mellersta Sverige   \n",
    "norra_sverige = [\"Umeå\"]\n",
    "mellersta_sverige = [\"Oxelösund\", \"Kungsör\", \"Hammarö\", \"Håbo\"]\n",
    "\n",
    "# Impute missing values in location\n",
    "df['location'] = df.apply(\n",
    "    lambda row: \"Norra Sverige\" if pd.isna(row['location']) and row['municipality'] in norra_sverige\n",
    "    else (\"Mellersta Sverige\" if pd.isna(row['location']) and row['municipality'] in mellersta_sverige \n",
    "          else row['location']),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Data Cleaning Continued \n",
    "\n",
    "# Imputing missing values in housing_association_fee in order of proximity \n",
    "# Firstly, calculating the mean of housing_association_fee for the first grouping level\n",
    "# Secondly, applying the mean to the rows that are in the specified group, and rounding housing_association_fee to the nearest whole number\n",
    "# Continuing to the next grouping step and so on until all missing values are filled in\n",
    "\n",
    "# Impute based on org_number first\n",
    "mean_fee_by_org = df.groupby('org_number')['housing_association_fee'].transform('mean')\n",
    "df['housing_association_fee'] = df['housing_association_fee'].fillna(mean_fee_by_org).round(0)\n",
    "\n",
    "# Impute based on postcode secondly\n",
    "mean_fee_by_postcode = df.groupby('postcode')['housing_association_fee'].transform('mean')\n",
    "df['housing_association_fee'] = df['housing_association_fee'].fillna(mean_fee_by_postcode).round(0)\n",
    "\n",
    "# Impute based on brokers description secondly\n",
    "mean_fee_by_brokers_construction = df.groupby('brokers_description')['housing_association_fee'].transform('mean')\n",
    "df['housing_association_fee'] = df['housing_association_fee'].fillna(mean_fee_by_brokers_construction).round(0)\n",
    "\n",
    "# Impute based on municipality thirdly\n",
    "mean_fee_by_municipality = df.groupby('municipality')['housing_association_fee'].transform('mean')\n",
    "df['housing_association_fee'] = df['housing_association_fee'].fillna(mean_fee_by_municipality).round(0)\n",
    "\n",
    "# Impute based on region fourthly\n",
    "mean_fee_by_region = df.groupby('region')['housing_association_fee'].transform('mean')\n",
    "df['housing_association_fee'] = df['housing_association_fee'].fillna(mean_fee_by_region).round(0)\n",
    "\n",
    "# Remaining missing values are filled with the overall mean\n",
    "overall_mean_fee = df['housing_association_fee'].mean()\n",
    "df['housing_association_fee'] = df['housing_association_fee'].fillna(overall_mean_fee).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Data Cleaning Continued \n",
    "\n",
    "# Imputing operating_cost in a similar way as the before, but now grouping by object type \n",
    "\n",
    "# Firstly, filling in missing values in operating_cost for non apartment objects only\n",
    "\n",
    "# Fill by org_number\n",
    "mean_operating_cost_by_org = df[df['object_type'] != 'Apartment'].groupby('org_number')['operating_cost'].mean()\n",
    "df['operating_cost'] = df['operating_cost'].fillna(df['org_number'].map(mean_operating_cost_by_org)).round(0)\n",
    "\n",
    "# Fill by postcode\n",
    "mean_operating_cost_by_postcode = df[df['object_type'] != 'Apartment'].groupby('postcode')['operating_cost'].mean()\n",
    "df['operating_cost'] = df['operating_cost'].fillna(df['postcode'].map(mean_operating_cost_by_postcode)).round(0)\n",
    "\n",
    "# Fill by brokers_description\n",
    "mean_operating_cost_by_brokers_description = df[df['object_type'] != 'Apartment'].groupby('brokers_description')['operating_cost'].mean()\n",
    "df['operating_cost'] = df['operating_cost'].fillna(df['brokers_description'].map(mean_operating_cost_by_brokers_description)).round(0)\n",
    "\n",
    "# Fill by municipality\n",
    "mean_operating_cost_by_municipality = df[df['object_type'] != 'Apartment'].groupby('municipality')['operating_cost'].mean()\n",
    "df['operating_cost'] = df['operating_cost'].fillna(df['municipality'].map(mean_operating_cost_by_municipality)).round(0)\n",
    "\n",
    "# Fill by region\n",
    "mean_operating_cost_by_region = df[df['object_type'] != 'Apartment'].groupby('region')['operating_cost'].mean()\n",
    "df['operating_cost'] = df['operating_cost'].fillna(df['region'].map(mean_operating_cost_by_region)).round(0)\n",
    "\n",
    "# Secondly, filling in missing values in operating_cost for Apartments only\n",
    "\n",
    "# Fill missing values in priority order \n",
    "\n",
    "# Fill by org_number\n",
    "mean_operating_cost_by_org = df[df['object_type'] == 'Apartment'].groupby('org_number')['operating_cost'].mean()\n",
    "df['operating_cost'] = df['operating_cost'].fillna(df['org_number'].map(mean_operating_cost_by_org)).round(0)\n",
    "\n",
    "# Fill by postcode\n",
    "mean_operating_cost_by_postcode = df[df['object_type'] == 'Apartment'].groupby('postcode')['operating_cost'].mean()\n",
    "df['operating_cost'] = df['operating_cost'].fillna(df['postcode'].map(mean_operating_cost_by_postcode)).round(0)\n",
    "\n",
    "# Fill by brokers_description\n",
    "mean_operating_cost_by_brokers_description = df[df['object_type'] == 'Apartment'].groupby('brokers_description')['operating_cost'].mean()\n",
    "df['operating_cost'] = df['operating_cost'].fillna(df['brokers_description'].map(mean_operating_cost_by_brokers_description)).round(0)\n",
    "\n",
    "# Fill by municipality\n",
    "mean_operating_cost_by_municipality = df[df['object_type'] == 'Apartment'].groupby('municipality')['operating_cost'].mean()\n",
    "df['operating_cost'] = df['operating_cost'].fillna(df['municipality'].map(mean_operating_cost_by_municipality)).round(0)\n",
    "\n",
    "# Fill by regions\n",
    "mean_operating_cost_by_region = df[df['object_type'] == 'Apartment'].groupby('region')['operating_cost'].mean()\n",
    "df['operating_cost'] = df['operating_cost'].fillna(df['region'].map(mean_operating_cost_by_region)).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Data Cleaning Continued \n",
    "\n",
    "# Floor levels range from -6 up to 100.\n",
    "# The negatives values seem to be wrongly specified, based on randomly looking up the sale information about some addresses.\n",
    "# The highest floors are also wrongly specified, sinces the highest floor level in an apartment building in Sweden was 50 before 2023. \n",
    "\n",
    "# Adjusting floor level\n",
    "df['floor'] = df['floor'].apply(lambda x: abs(x) if x <= -1 else (50 if x >= 50 else x)) \n",
    "\n",
    "# Calculate the mean floor value for apartments\n",
    "mean_floor_apartment = df.loc[df['object_type'] == 'Apartment', 'floor'].mean()\n",
    "\n",
    "# Impute missing floor values\n",
    "df['floor'] = df.apply(\n",
    "    lambda row: mean_floor_apartment \n",
    "    if pd.isna(row['floor']) and row['object_type'] == 'Apartment' \n",
    "    else (0 if pd.isna(row['floor']) else row['floor']),\n",
    "    axis=1)\n",
    "\n",
    "# Rounding floor to the nearest whole number\n",
    "df['floor'] = df['floor'].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Data Cleaning Continued \n",
    "\n",
    "# Imputing missing values amenities, key, has_fireplace and has_balcony\n",
    "\n",
    "# Amenities \n",
    "# Check for missing values in 'amenities'\n",
    "missing_mask = df['amenities'].isna() \n",
    "\n",
    "# One-hot encode the 'amenities' column\n",
    "one_hot = df['amenities'].fillna('').str.get_dummies(sep=',') \n",
    "\n",
    "# Adding amenities_ infront the one-hot encoded variables \n",
    "one_hot = one_hot.add_prefix('amenities_') \n",
    "\n",
    "# Reintroduce missing values in the one-hot encoded columns\n",
    "one_hot[missing_mask] = np.nan \n",
    "\n",
    "# Join the one-hot encoded columns with the original df\n",
    "df = pd.concat([df, one_hot], axis=1) \n",
    "\n",
    "# Key \n",
    "# Check for missing values in 'key'\n",
    "missing_mask = df['key'].isna() \n",
    "\n",
    "# One-hot encode the 'key' column\n",
    "one_hot = df['key'].fillna('').str.get_dummies(sep=',') \n",
    "\n",
    "# Adding key_ infront the one-hot encoded variables \n",
    "one_hot = one_hot.add_prefix('key_') \n",
    "\n",
    "# Reintroduce missing values in the one-hot encoded columns\n",
    "one_hot[missing_mask] = np.nan  \n",
    "\n",
    "# Join the one-hot encoded columns with the original df\n",
    "df = pd.concat([df, one_hot], axis=1) \n",
    "\n",
    "# Combining relevant columns created, from the step above, together \n",
    "\n",
    "# Filling in has_fireplace with values from key_fireplace and amenities_fireplace\n",
    "df['has_fireplace'] = (df['has_fireplace']\n",
    "                       .combine_first(df['key_fireplace'])         # Use key_fireplace if has_fireplace is NaN \n",
    "                       .combine_first(df['amenities_fireplace']))  # Use amenities_fireplace if both are NaN\n",
    "\n",
    "# Dropping key_fireplace and amenities_fireplace\n",
    "df = df.drop(['key_fireplace', 'amenities_fireplace'], axis=1) \n",
    "\n",
    "# Filling in has_balcony with values from amenities_balcony and key_balcony\n",
    "df['has_balcony'] = (\n",
    "    df['has_balcony']\n",
    "    .combine_first(df['amenities_balcony'])  # Use amenities_balcony if has_balcony is NaN\n",
    "    .combine_first(df['key_balcony']))       # Use key_balcony if both are NaN\n",
    "\n",
    "# Dropping amenities_balcony and key_balcony\n",
    "df = df.drop(['amenities_balcony', 'key_balcony'], axis=1) \n",
    "\n",
    "# Filling in has_patio with values from amenities_patio and key_patio\n",
    "df['has_patio'] = (\n",
    "    df['has_patio']\n",
    "    .combine_first(df['amenities_patio'])  # Use amenities_patio if has_patio is NaN\n",
    "    .combine_first(df['key_patio']))       # Use key_patio if both are NaN\n",
    "\n",
    "# Dropping amenities_patio and key_patio\n",
    "df = df.drop(['amenities_patio', 'key_patio'], axis=1) \n",
    "\n",
    "# Filling in amenities_elevator with values from key_elevator\n",
    "df['amenities_elevator'] = (\n",
    "    df['amenities_elevator']\n",
    "    .combine_first(df['key_elevator']))  # Use key_elevator if amenities_elevator is NaN\n",
    "\n",
    "# Dropping original amenities and key columns, and key_elevator\n",
    "df = df.drop(['amenities', 'key', 'key_elevator'], axis=1) \n",
    "\n",
    "# Renaming columns for consistency reasons\n",
    "df.rename(columns={'amenities_elevator': 'has_elevator', 'amenities_[]': 'has_other_amenities'}, inplace=True)\n",
    "\n",
    "# Imputing has_balcony, has_fireplace, has_patio, has_solar_panels, has_elevator, has_other_amenities\n",
    "# List of binary features to impute\n",
    "binary_features = ['has_balcony', 'has_fireplace', 'has_patio', 'has_solar_panels', 'has_elevator', 'has_other_amenities'] \n",
    "\n",
    "# Creating a for loop that fills in the missing values for each column in binary_features. Imputing based on org_number\n",
    "for feature in binary_features:\n",
    "    org_numbers_with_feature = df.loc[df[feature] == 1, 'org_number'].unique() # Identify org_numbers where the feature is 1\n",
    "    df.loc[df['org_number'].isin(org_numbers_with_feature), feature] = 1       # Set the feature to 1 for all rows with those org_numbers\n",
    "\n",
    "# Update 'has_balcony' to 0 where 'floor' is 0 and 'has_balcony' is not already NaN\n",
    "df.loc[(df['floor'] == 0) & (df['has_balcony'].notna()), 'has_balcony'] = 0 \n",
    "\n",
    "# Preparing for one hot encoding \n",
    "\n",
    "# Specififying which columns to transform into text string representation \n",
    "columns_to_transform = ['has_fireplace', 'has_balcony', 'has_patio', 'has_solar_panels', 'has_elevator', 'has_other_amenities']\n",
    "\n",
    "# Creating a foor loop where 1 is changed to yes, 0 to no, and missing values are filled with unknown\n",
    "for column in columns_to_transform:\n",
    "    df[column] = df[column].replace({1: 'yes', 0: 'no'}).fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Data Cleaning Continued \n",
    "\n",
    "# Firstly, filling in missing values in living area for all non apartment objects only\n",
    "\n",
    "# Firstly, filling in missing values for each object type, excluding Aparjectment, by object_type grouping and taking the mean for each object_type\n",
    "mean_living_area = df[df['object_type'] != 'Apartment'].groupby('object_type')['living_area'].mean()\n",
    "\n",
    "# Fill N/A values in 'living_area' based on the mean for specific object types, still excluding Apartment\n",
    "df['living_area'] = df.apply(\n",
    "    lambda row: mean_living_area[row['object_type']] \n",
    "    if pd.isna(row['living_area']) and row['object_type'] in mean_living_area \n",
    "    else row['living_area'],\n",
    "    axis=1)\n",
    "\n",
    "# Secondly, filling in missing values in living area for all Apartments only\n",
    "\n",
    "# Define grouping columns for imputing living_area\n",
    "group_columns = ['org_number', 'postcode', 'brokers_description', 'municipality']\n",
    "\n",
    "# For loop that will iterate over the grouping columns, and that will calculate the mean living_area for Apartment for each group \n",
    "# and then impute missing values using the calculated means. \n",
    "for group_col in group_columns:\n",
    "    \n",
    "    # Calculate the mean living_area for Apartment for each group \n",
    "    mean_living_area = (\n",
    "        df[df['object_type'] == 'Apartment']\n",
    "        .groupby(group_col)['living_area']\n",
    "        .mean())\n",
    "    \n",
    "    # Impute missing 'living_area' using the calculated means\n",
    "    df['living_area'] = df.apply(\n",
    "        lambda row: mean_living_area[row[group_col]]\n",
    "        if pd.isna(row['living_area']) and row['object_type'] == 'Apartment' and row[group_col] in mean_living_area\n",
    "        else row['living_area'],\n",
    "        axis=1)\n",
    "    \n",
    "# Rounding asking_price to the nearest whole number\n",
    "df['living_area'] = df['living_area'].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Data Cleaning Continued \n",
    "\n",
    "# Based on living_area that has been imputed, we will fill in missing values in asking price \n",
    "\n",
    "# Price per sqm which is based on imputed living_area\n",
    "df['price_per_sqm'] = df['asking_price'] / df['living_area']\n",
    "\n",
    "# Defining a list of columns in the order we want to iterate them in\n",
    "group_columns = ['org_number', 'postcode', 'brokers_description' ,'municipality', 'region']\n",
    "\n",
    "# Impute missing asking_price iteratively for each group\n",
    "for group_col in group_columns:\n",
    "\n",
    "    # Calculate the mean price_per_sqm for each group\n",
    "    mean_price_per_sqm = df.groupby(group_col)['price_per_sqm'].transform(lambda x: x.mean() if x.notna().any() else np.nan)\n",
    "    \n",
    "    # Filling missing asking_price using mean price_per_sqm and living_area:\n",
    "    df['asking_price'] = df['asking_price'].fillna(df['living_area'] * mean_price_per_sqm)\n",
    "\n",
    "# Rounding asking_price to the nearest whole number\n",
    "df['asking_price'] = df['asking_price'].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Data Cleaning Continued \n",
    "\n",
    "# Convert 'sell_year' from integer to string\n",
    "df['sell_year'] = df['sell_year'].astype(str) \n",
    "\n",
    "# Convert 'construction_year' from integer to string\n",
    "df['construction_year'] = df['construction_year'].astype(str) \n",
    "\n",
    "# Fill missing values in association_tax_liability with unknown\n",
    "df['association_tax_liability'] = df['association_tax_liability'].fillna('unknown')\n",
    "\n",
    "# Dropping variables that were not imputed, because they either had to many missing values or a low correlation with sell_price\n",
    "# And dropping unnecessary identification IDs too \n",
    "df = df.drop(['additional_area', 'agency_id', 'brokers_description', 'cover_photo_description','customer_area_description', 'district', 'energy_class', \n",
    "              'height', 'org_number', 'id2', 'index', 'is_new_construction', 'locality', 'plot_area', 'populated_area', 'street_address', 'width', \n",
    "              'price_per_sqm', 'municipality', 'number_of_units', 'total_living_area', 'total_plot_area', 'living_area'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 - Modelling \n",
    "\n",
    "# Sorting our df in descending order and putting NaNs at then end\n",
    "df = df.sort_values(by=['sell_price'], ascending=False, na_position='first') \n",
    "\n",
    "# Extracting 'id' that will be used for the JSON fil\n",
    "missing_sell_price_count = df['sell_price'].isna().sum()\n",
    "df_id_predicted_sell_price = df['id'].head(missing_sell_price_count)\n",
    "\n",
    "# Dropping 'id' from the df that will be used for modelling  \n",
    "df = df.drop(['id'], axis=1)\n",
    "\n",
    "# Automatically detect continuous variables except for 'sell_price' \n",
    "continuous_vars = [\n",
    "    col for col in df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    if col != 'sell_price'\n",
    "    ]\n",
    "\n",
    "# Apply StandardScaler to the continuous variables detected \n",
    "df[continuous_vars] = StandardScaler().fit_transform(df[continuous_vars])\n",
    "\n",
    "# One Hot Encoding\n",
    "df = pd.get_dummies(df, dtype=int)\n",
    "\n",
    "# Create a new df with rows where 'sell_price' is missing\n",
    "df_with_null = df[df['sell_price'].isna()]\n",
    "\n",
    "# Remove missing rows in sell_price from the original df\n",
    "df_without_null = df[df['sell_price'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 - Modelling \n",
    "\n",
    "# Outlier handling in sell_price. The dataset is filtered to include only those instances where the sale price falls between the 1st and 99th percentiles.\n",
    "max_threshold = df_without_null['sell_price'].quantile(0.99)\n",
    "min_threshold = df_without_null['sell_price'].quantile(0.01)\n",
    "df_without_null = df_without_null[(df_without_null['sell_price'] < max_threshold) & (df_without_null['sell_price'] > min_threshold)]\n",
    "\n",
    "# Features \n",
    "X = df_without_null.drop('sell_price', axis=1)  \n",
    "\n",
    "# Target\n",
    "y = df_without_null['sell_price']              \n",
    "\n",
    "# Splitting the data into training (90%) and testing (10%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.06, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=10, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.06, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=10, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.06, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=10, ...)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 3 - Modelling \n",
    "\n",
    "# XGBoost\n",
    "\n",
    "# Use XGBRegressor for regression\n",
    "xgboost_model = xgb.XGBRegressor(\n",
    "    subsample = 1.0, \n",
    "    n_estimators = 1000, \n",
    "    max_depth = 9, \n",
    "    learning_rate = 0.06, \n",
    "    colsample_bytree = 1.0, \n",
    "    random_state = 10)  \n",
    "\n",
    "# Fitting the model to the training data\n",
    "xgboost_model.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4 - Prediction\n",
    "\n",
    "# Creating a new dataframe from the df with missing values for the sell_price\n",
    "X_with_null = df_with_null.drop('sell_price', axis=1)\n",
    "\n",
    "# Predicting the missing sell_price values \n",
    "predicted_sell_price = xgboost_model.predict(X_with_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      id  predicted_sell_price\n",
      "596198  3fccf28bb678790528321f4589748a65           1952873.375\n",
      "596202  7a72ef2f0bdaa0fbb5d1dfd8332b732b           7987848.000\n",
      "596218  a938919c37d288a62e1c3f03f2158728           2751635.250\n",
      "596222  6cfec1ad18f17bf99da6514b6f300c4d           8261725.500\n",
      "596223  41688fb0a6d94d4dc84d0d3164d34fad           3099260.000\n",
      "...                                  ...                   ...\n",
      "668790  ffbee97ea37e1e3fb66cfa6d12840910           2175783.250\n",
      "668793  ffd1af5bf80631fc8d3fb34cc90e007d            582606.750\n",
      "668794  ffdba22478f015bff377f2677748d683           2555724.500\n",
      "668796  ffe14bd66d76d39954e2e85930f0f025           7730961.000\n",
      "668798  ffedd6c01b74454dff0dee1375b1846e           3220350.250\n",
      "\n",
      "[19255 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# STEP 5 - JSON\n",
    "\n",
    "# predicted_sell_price should have the same index as X_with_null\n",
    "predicted_sell_price = pd.DataFrame(predicted_sell_price, index=X_with_null.index)\n",
    "\n",
    "# Add the predictions back to the dataframe\n",
    "X_with_null['predicted_sell_price'] = predicted_sell_price\n",
    "\n",
    "# Combine with ID\n",
    "final = pd.concat([df_id_predicted_sell_price, X_with_null], axis=1)\n",
    "\n",
    "# Dropping everything except 'id' and 'predicted_sell_price'\n",
    "final = final[['id', 'predicted_sell_price']]\n",
    "\n",
    "# Here we convert the cleaned dataframe to a list of dictionaries:\n",
    "list_of_dictionaries = final.to_dict(orient='records')\n",
    "\n",
    "# Specifying the output file name to my student number as in the instructions:\n",
    "output_filename = 'assignment3_25199.json'\n",
    "\n",
    "# Writing the list of dictionaries to a JSON file with my assigned file name:\n",
    "with open(output_filename, 'w') as file:\n",
    "    json.dump(list_of_dictionaries, file, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
